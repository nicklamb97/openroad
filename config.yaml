chat:
  context: default
  greedy_mode: false
  logs_dir: data/chatlogs
  max_tokens: null
  model: models/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf
  session: null
  vi_mode: false
  visible_overflow: true
general:
  log_level: INFO
generate:
  chunk_word_count: 1000
  model: models/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf
  num_cpus: 10
  num_instructions: 40
  output_dir: generated
  prompt_file: prompt.txt
  seed_file: seed_tasks.json
  taxonomy_base: origin/main
  taxonomy_path: taxonomy
serve:
  gpu_layers: -1
  host_port: 127.0.0.1:8000
  max_ctx_size: 30000
  model_path: models/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf
